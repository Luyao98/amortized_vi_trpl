Traceback (most recent call last):
  File "/home/luyao/amortized_vi_trpl/GMM/GMM_model.py", line 188, in <module>
    train_model(model, target, n_epochs, batch_size, n_context, n_components, eps, beta, optimizer)
  File "/home/luyao/amortized_vi_trpl/GMM/GMM_model.py", line 115, in train_model
    log_model_j = likelihood(mean_pred_j, cov_pred_j, model_samples[:, j,])
  File "/home/luyao/amortized_vi_trpl/Gaussian/utils.py", line 96, in likelihood
    return ch.distributions.MultivariateNormal(mean, cov).log_prob(samples)
  File "/home/luyao/miniconda3/envs/ITPAL_luyao/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py", line 150, in __init__
    super(MultivariateNormal, self).__init__(batch_shape, event_shape, validate_args=validate_args)
  File "/home/luyao/miniconda3/envs/ITPAL_luyao/lib/python3.7/site-packages/torch/distributions/distribution.py", line 57, in __init__
    f"Expected parameter {param} "
ValueError: Expected parameter covariance_matrix (Tensor of shape (64, 2, 2)) of distribution MultivariateNormal(loc: torch.Size([64, 2]), covariance_matrix: torch.Size([64, 2, 2])) to satisfy the constraint PositiveDefinite(), but found invalid values:
tensor([[[0.1568, 0.1755],
         [0.1755, 1.4398]],
        [[0.2476, 0.1176],
         [0.1176, 0.2142]],
        [[0.8091, 0.3872],
         [0.3872, 1.3259]],
        [[1.3328, 0.7781],
         [0.7781, 1.4216]],
        [[0.2034, 0.1341],
         [0.1341, 0.1103]],
        [[1.5360, 0.8013],
         [0.8013, 0.7067]],
        [[1.3925, 0.7919],
         [0.7919, 1.3347]],
        [[0.1610, 0.1527],
         [0.1527, 0.8804]],
        [[0.2143, 0.1304],
         [0.1304, 0.0794]],
        [[0.2445, 0.1207],
         [0.1207, 0.1759]],
        [[0.5543, 0.2340],
         [0.2340, 1.0095]],
        [[1.9321, 0.8360],
         [0.8360, 0.6044]],
        [[2.0156, 0.8505],
         [0.8505, 0.7749]],
        [[2.1873, 0.8790],
         [0.8790, 1.2539]],
        [[1.4964, 0.8074],
         [0.8074, 1.0842]],
        [[2.2651, 0.8949],
         [0.8949, 1.4340]],
        [[1.4119, 0.7959],
         [0.7959, 1.3038]],
        [[2.3390, 0.9103],
         [0.9103, 1.6016]],
        [[1.5803, 0.8028],
         [0.8028, 0.5047]],
        [[1.5135, 0.8004],
         [0.8004, 0.8503]],
        [[0.5716, 0.2456],
         [0.2456, 1.0392]],
        [[1.9096, 0.8320],
         [0.8320, 0.5659]],
        [[0.1540, 0.1885],
         [0.1885, 1.8094]],
        [[1.8085, 0.8166],
         [0.8166, 0.4334]],
        [[1.1442, 0.6508],
         [0.6508, 1.5302]],
        [[1.5865, 0.8029],
         [0.8029, 0.4870]],
        [[0.1603, 0.1595],
         [0.1595, 1.0498]],
        [[0.1812, 0.1407],
         [0.1407, 0.3228]],
        [[0.3841, 0.1327],
         [0.1327, 0.5707]],
        [[2.0180, 0.8509],
         [0.8509, 0.7805]],
        [[0.1673, 0.1471],
         [0.1471, 0.6268]],
        [[0.4354, 0.1466],
         [0.1466, 0.6679]],
        [[1.9490, 0.8389],
         [0.8389, 0.6353]],
        [[1.5925, 0.8029],
         [0.8029, 0.4717]],
        [[0.1559, 0.1796],
         [0.1796, 1.5518]],
        [[1.0693, 0.5442],
         [0.5442, 1.4865]],
        [[0.2011, 0.1348],
         [0.1348, 0.1224]],
        [[1.8867, 0.8279],
         [0.8279, 0.5299]],
        [[0.1638, 0.1503],
         [0.1503, 0.7617]],
        [[0.2467, 0.1148],
         [0.1148, 0.3756]],
        [[0.1593, 0.1643],
         [0.1643, 1.1603]],
        [[1.5354, 0.8013],
         [0.8013, 0.7104]],
        [[1.5391, 0.8014],
         [0.8014, 0.6895]],
        [[1.0051, 0.4989],
         [0.4989, 1.4541]],
        [[0.2234, 0.1271],
         [0.1271, 0.0870]],
        [[2.0937, 0.8637],
         [0.8637, 0.9724]],
        [[1.2399, 0.7420],
         [0.7420, 1.5360]],
        [[1.8180, 0.8176],
         [0.8176, 0.4428]],
        [[2.1244, 0.8687],
         [0.8687, 1.0594]],
        [[0.3947, 0.1354],
         [0.1354, 0.5863]],
        [[0.1598, 0.1618],
         [0.1618, 1.1028]],
        [[0.2485, 0.1143],
         [0.1143, 0.3175]],
        [[0.1805, 0.1409],
         [0.1409, 0.3333]],
        [[1.2803, 0.7582],
         [0.7582, 1.4854]],
        [[1.7389, 0.8092],
         [0.8092, 0.3883]],
        [[0.6367, 0.2867],
         [0.2867, 1.1310]],
        [[1.5085, 0.8002],
         [0.8002, 0.8861]],
        [[2.0543, 0.8570],
         [0.8570, 0.8682]],
        [[2.3376, 0.9100],
         [0.9100, 1.5983]],
        [[2.0541, 0.8570],
         [0.8570, 0.8678]],
        [[0.9876, 0.4888],
         [0.4888, 1.4430]],
        [[0.8795, 0.4273],
         [0.4273, 1.3734]],
        [[0.8032, 0.3837],
         [0.3837, 1.3195]],
        [[1.6384, 0.7977],
         [0.7977, 0.4001]]], grad_fn=<ExpandBackward0>)