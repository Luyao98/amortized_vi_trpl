Traceback (most recent call last):
  File "/home/luyao/amortized_vi_trpl/GMM/test.py", line 176, in <module>
    train_model(model, target, n_epochs, batch_size, n_context, n_components, eps_mean, eps_cov, alpha, optimizer)
  File "/home/luyao/amortized_vi_trpl/GMM/test.py", line 119, in train_model
    loss.backward()
  File "/home/luyao/miniconda3/envs/ITPAL_luyao/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/luyao/miniconda3/envs/ITPAL_luyao/lib/python3.7/site-packages/torch/autograd/__init__.py", line 190, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/luyao/miniconda3/envs/ITPAL_luyao/lib/python3.7/site-packages/torch/autograd/__init__.py", line 85, in _make_grads
    raise RuntimeError("grad can be implicitly created only for scalar outputs")
RuntimeError: grad can be implicitly created only for scalar outputs