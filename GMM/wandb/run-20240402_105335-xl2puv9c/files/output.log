
Epoch 5: KL Divergence = 7.2656965255737305
Epoch 10: KL Divergence = 7.186087131500244
Epoch 15: KL Divergence = 7.749709129333496
Epoch 20: KL Divergence = 7.720558166503906
Epoch 25: KL Divergence = 8.341538429260254
Epoch 30: KL Divergence = 7.976716041564941
Epoch 35: KL Divergence = 8.624031066894531
Epoch 40: KL Divergence = 8.560729026794434
Epoch 45: KL Divergence = 8.57065200805664
Epoch 50: KL Divergence = 8.479117393493652
Training done!
contexts: tensor([[-0.1174],
        [ 1.8359],
        [ 1.0457]])
target mean: tensor([[[-1.1714,  9.9312]],
        [[ 9.6507, -2.6201]],
        [[ 8.6530,  5.0126]]])
weight here [[1.]
 [1.]
 [1.]]
model mean: [[[-2.6339138   0.14530948]]
 [[-2.6271667   0.14667815]]
 [[-2.6264374   0.14608303]]]