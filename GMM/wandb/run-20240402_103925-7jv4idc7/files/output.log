
Epoch 5: KL Divergence = 6.911911487579346
Epoch 10: KL Divergence = 7.517755031585693
Epoch 15: KL Divergence = 7.950989723205566
Epoch 20: KL Divergence = 8.193382263183594
Epoch 25: KL Divergence = 8.33873176574707
Epoch 30: KL Divergence = 8.640398979187012
Epoch 35: KL Divergence = 9.024284362792969
Epoch 40: KL Divergence = 8.71882152557373
Epoch 45: KL Divergence = 9.110965728759766
Epoch 50: KL Divergence = 9.374171257019043
Training done!
contexts: tensor([[-1.0615],
        [ 2.1705],
        [-0.2720]])
target mean: tensor([[[-8.7310,  4.8755]],
        [[ 8.2552, -5.6437]],
        [[-2.6866,  9.6324]]])
weight here [[1.]
 [1.]
 [1.]]
model mean: [[[-3.0723653   0.32178968]]
 [[-3.0484865   0.32374048]]
 [[-3.0600362   0.32322738]]]