# training config
n_epochs: 2000
batch_size: 128
n_context: 1280
num_gate_layer: 3
num_component_layer: 5
n_samples: 5
gate_lr: 0.001
gaussian_lr: 0.01
gate_strategy: 3.3
history_size: 100

# model config
model_name: "toy_task_model_3"
dim: 2
context_dim: 2
random_init: True
initialization_type: "xavier"
max_components: 8
init_components: 8

# target config
target_name: "gmm"
target_components: 6
